{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef7688d4",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification Machine – Software Artefact\n",
    "\n",
    "## Introduction\n",
    "This artefact documents the full machine learning workflow used to build a breast cancer classification model. The goal is to predict whether a tumour is *Benign* or *Malignant* using clinical features from the Breast Cancer Wisconsin dataset.\n",
    "\n",
    "This notebook includes:\n",
    "- Data loading and inspection  \n",
    "- Cleaning and preprocessing  \n",
    "- Feature engineering  \n",
    "- Model training  \n",
    "- Evaluation  \n",
    "- Exporting the trained model for deployment in a Flask web app  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d29e4",
   "metadata": {},
   "source": [
    "Import Libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2eedce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries for data handling,\n",
    "#preprocessing, model training, and evaluate.\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb671a8e",
   "metadata": {},
   "source": [
    "Load Datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a59a7cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 32),\n",
       "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       " 0    842302         M        17.99         10.38          122.80     1001.0   \n",
       " 1    842517         M        20.57         17.77          132.90     1326.0   \n",
       " 2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       " 3  84348301         M        11.42         20.38           77.58      386.1   \n",
       " 4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       " \n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       " 0          0.11840           0.27760          0.3001              0.14710   \n",
       " 1          0.08474           0.07864          0.0869              0.07017   \n",
       " 2          0.10960           0.15990          0.1974              0.12790   \n",
       " 3          0.14250           0.28390          0.2414              0.10520   \n",
       " 4          0.10030           0.13280          0.1980              0.10430   \n",
       " \n",
       "    ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       " 0  ...         25.38          17.33           184.60      2019.0   \n",
       " 1  ...         24.99          23.41           158.80      1956.0   \n",
       " 2  ...         23.57          25.53           152.50      1709.0   \n",
       " 3  ...         14.91          26.50            98.87       567.7   \n",
       " 4  ...         22.54          16.67           152.20      1575.0   \n",
       " \n",
       "    smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       " 0            0.1622             0.6656           0.7119                0.2654   \n",
       " 1            0.1238             0.1866           0.2416                0.1860   \n",
       " 2            0.1444             0.4245           0.4504                0.2430   \n",
       " 3            0.2098             0.8663           0.6869                0.2575   \n",
       " 4            0.1374             0.2050           0.4000                0.1625   \n",
       " \n",
       "    symmetry_worst  fractal_dimension_worst  \n",
       " 0          0.4601                  0.11890  \n",
       " 1          0.2750                  0.08902  \n",
       " 2          0.3613                  0.08758  \n",
       " 3          0.6638                  0.17300  \n",
       " 4          0.2364                  0.07678  \n",
       " \n",
       " [5 rows x 32 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Breast Cancer Wisconsin Diagnostic dataset. \n",
    "# This dataset contains 30 numerical tumour features \n",
    "# and a binary diagnosis label (M = malignant, B = benign).\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"breast_cancer_diagnostic.csv\")\n",
    "\n",
    "# Display the first few rows to confirm successful loading\n",
    "df.shape, df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f027b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "# Display the feature columns used for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a3f611d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
       "       'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns\n",
    "# Show the list of feature names in X.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f63d8ea",
   "metadata": {},
   "source": [
    "## Inspecting Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a595fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset shape, column names, and basic info. \n",
    "# This helps confirm that the dataset is clean and complete.\n",
    "\n",
    "df.shape\n",
    "df.info()\n",
    "df.describe()\n",
    "df.isnull().sum()    # Verify no missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb791bf",
   "metadata": {},
   "source": [
    "Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030de599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows containing missing values. \n",
    "# The diagnostic dataset normally has no NaNs, but this step \n",
    "# ensures the dataframe is clean if additional data is added. \n",
    "# (Alternatively, imputation could be used instead of dropping.)\n",
    "\n",
    "df = df.dropna()  # or impute if needed\n",
    "\n",
    "# Remove duplicate rows to prevent data leakage and ensure \n",
    "# the model is trained on unique, non-redundant samples.\n",
    "df = df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0cccd",
   "metadata": {},
   "source": [
    "Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378154b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 31), (569,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target variable and remove non‑predictive columns. \n",
    "# 'id' is removed because it does not contain clinical information.\n",
    "\n",
    "TARGET = \"diagnosis\"\n",
    "\n",
    "X = df.drop([\"id\", TARGET], axis=1)     # 30 numerical features\n",
    "                                        # Target labels (M/B)\n",
    "y = df[TARGET]\n",
    "\n",
    "# Confirm feature count\n",
    "X.shape, y.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28eb9bc",
   "metadata": {},
   "source": [
    "Train Test/Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1802264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test/Split Data\n",
    "# Split the dataset into training and testing sets.\n",
    "# test_size=0.2 means 20% of data is used for evaluation.\n",
    "# random_state ensures reproducibility.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2276f89",
   "metadata": {},
   "source": [
    "Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "403839e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize numerical features so they have mean=0 and std=1. \n",
    "# This improves model performance and stability.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5023e34",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51aac5f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a RandomForestClassifier on the scaled training data. \n",
    "# Random Forest is robust, handles non-linear patterns, \n",
    "# and performs well on medical datasets.\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91639236",
   "metadata": {},
   "source": [
    "Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bf492e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70  1]\n",
      " [ 3 40]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.97        71\n",
      "           M       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the test set and evaluate accuracy.\n",
    "# Also display confusion matrix and classification report \n",
    "# for deeper performance analysis.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f77ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9649122807017544\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70  1]\n",
      " [ 3 40]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.99      0.97        71\n",
      "           M       0.98      0.93      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"breast_cancer_diagnostic.csv\")\n",
    "\n",
    "# Prepare data\n",
    "TARGET = \"diagnosis\"\n",
    "X = df.drop([\"id\", TARGET], axis=1)\n",
    "y = df[TARGET]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec59ec72",
   "metadata": {},
   "source": [
    "Save the Model for Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec1cbe8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model and scaler so they can be loaded \n",
    "# by the Flask web application for real-time predictions.\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"breast_cancer_unified_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd72970",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This artefact demonstrates the full machine learning workflow used to create the Breast Cancer Classification Machine. The trained model was exported and integrated into a Flask web application, allowing real‑time predictions through a user‑friendly interface.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (py37)",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
